{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "611e1720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "from torch import nn, optim, utils, device as device_, cuda\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import sparseconvnet as scn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f69b6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = datasets.MNIST(\n",
    "    './data', \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=transforms.ToTensor())\n",
    "dataset_valid = datasets.MNIST(\n",
    "    './data', \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = utils.data.DataLoader(dataset_train,\n",
    "                                          batch_size=1000,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)\n",
    "dataloader_valid = utils.data.DataLoader(dataset_valid,\n",
    "                                          batch_size=1000,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "001259c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = utils.data.DataLoader(dataset_train,\n",
    "                                         collate_fn=train_merge,\n",
    "                                          batch_size=1,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "40c1aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(torch.utils.data.Dataset):\n",
    "    def __init__(self,file):\n",
    "        torch.utils.data.Dataset.__init__(self)\n",
    "        \n",
    "        N_DATA = 100\n",
    "        \n",
    "        data = torch.load(file)\n",
    "        self.data = []\n",
    "        # self.data = data[0] # array of img tensors\n",
    "        self.labels = data[1] # array of labels\n",
    "        \n",
    "        for i, img in enumerate(data[0]): # for each data\n",
    "            \n",
    "            if i >= N_DATA: break\n",
    "                \n",
    "            coords = []\n",
    "            features = []\n",
    "            for y in range(len(img)): # for y coordinates\n",
    "                for x in range(len(img[y])): # for x coordinates\n",
    "                    if img[y][x] != 0:\n",
    "                        coords.append(torch.LongTensor([y, x]))\n",
    "                        features.append(img[y][x].float())\n",
    "            \n",
    "            single_data = {}\n",
    "            single_data['coords'] = torch.stack(coords)\n",
    "            single_data['features'] = torch.stack(features)\n",
    "            self.data.append(single_data)\n",
    "        \n",
    "        for i,x in enumerate(self.data):\n",
    "            x['idx'] = i\n",
    "        \n",
    "        print('Loaded ', len(self.data), ' points')\n",
    "                \n",
    "    \n",
    "    def __getitem__(self, n):\n",
    "        return self.data[n], self.labels[n]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c71fe618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  100  points\n"
     ]
    }
   ],
   "source": [
    "dataset = Data('data/MNIST/processed/training.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f7bfb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainMergeFn(tbl, spatial_size=28):\n",
    "    \n",
    "    # tbl has batch_size data\n",
    "    \n",
    "    locations = []\n",
    "    features = []\n",
    "    targets = []\n",
    "    \n",
    "    for data, labels in tbl:\n",
    "        \"\"\"\n",
    "        coords = \n",
    "            tensor([[ x1, y1,  0],\n",
    "            [ x2, y2,  0]])\n",
    "        x y coordinates plus data index number\n",
    "        \"\"\"\n",
    "        coords = torch.cat([data['coords'].long(), torch.LongTensor([data['idx']]).expand([data['coords'].size(0), 1])], 1)\n",
    "        locations.append(coords)\n",
    "        features.append(data['features'])\n",
    "        targets.append(labels)\n",
    "\n",
    "    # return {'input': scn.InputLayerInput(torch.cat(locations, 0), torch.cat(features, 0)), 'target':torch.LongTensor(targets)}\n",
    "    # return scn.batch_location_tensors(locations), torch.cat(features, 0), torch.LongTensor(targets)\n",
    "    return torch.cat(locations, 0), torch.cat(features, 0), torch.LongTensor(targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "dfe1f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(dataset, collate_fn=TrainMergeFn, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c6d849c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 5, 12,  0],\n",
      "        [ 5, 13,  0],\n",
      "        [ 5, 14,  0],\n",
      "        ...,\n",
      "        [23, 10,  9],\n",
      "        [23, 11,  9],\n",
      "        [23, 12,  9]]), tensor([  3.,  18.,  18.,  ..., 122., 252.,  82.]), tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4]))\n"
     ]
    }
   ],
   "source": [
    "for i in dataloader_train:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b786d27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = device_(\"cuda\" if cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "47af0d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        data_dimension = 0\n",
    "        data_fullscale = 28*28\n",
    "        m = 4\n",
    "        self.input = scn.InputLayer(data_dimension,data_fullscale, mode=0)\n",
    "        self.conv = scn.SubmanifoldConvolution(data_dimension, 3, m, 3, False)\n",
    "        self.out = scn.OutputLayer(10)\n",
    "        \n",
    "#         self.sparseModel = scn.Sequential().add(\n",
    "#            scn.InputLayer(data_dimension,data_fullscale, mode=0)).add(\n",
    "#            scn.SubmanifoldConvolution(data_dimension, 3, m, 3, False)).add(\n",
    "#            scn.BatchNormReLU(m)).add(\n",
    "#            scn.OutputLayer(1))\n",
    "        self.linear = nn.Linear(m, 10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x=self.sparseModel(x)\n",
    "        x=self.input(x)\n",
    "        x=self.conv(x)\n",
    "        x=self.out(x)\n",
    "        x=self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e1bed9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_epochs': 20, 'initial_lr': 0.1, 'lr_decay': 0.02, 'weight_decay': 0.0001, 'momentum': 0.9, 'check_point': False, 'epoch': 1}\n",
      "#parameters 62\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "\n",
    "\n",
    "p={}\n",
    "p['n_epochs'] = 20\n",
    "p['initial_lr'] = 1e-1\n",
    "p['lr_decay'] = 0.02\n",
    "p['weight_decay'] = 1e-4\n",
    "p['momentum'] = 0.9\n",
    "p['check_point'] = False\n",
    "p['epoch']=1\n",
    "device = 'cuda:0'\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(),\n",
    "    lr=p['initial_lr'],\n",
    "    momentum = p['momentum'],\n",
    "    weight_decay = p['weight_decay'],\n",
    "    nesterov=True)\n",
    "\n",
    "print(p)\n",
    "print('#parameters', sum([x.nelement() for x in model.parameters() ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7cadd832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5, 12,  0],\n",
      "        [ 5, 13,  0],\n",
      "        [ 5, 14,  0],\n",
      "        ...,\n",
      "        [23, 10,  9],\n",
      "        [23, 11,  9],\n",
      "        [23, 12,  9]])\n",
      "tensor([  3.,  18.,  18.,  ..., 122., 252.,  82.])\n",
      "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sparseconvnet.SCN' has no attribute 'Metadata_0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_206/2312738938.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtargets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38spn/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_206/2626327569.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# x=self.sparseModel(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py38spn/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/d/Documents/UCSD/SuLab/SparseConvNet/SparseConvNet/sparseconvnet/ioLayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         output = SparseConvNetTensor(\n\u001b[0;32m---> 53\u001b[0;31m             metadata=Metadata(\n\u001b[0m\u001b[1;32m     54\u001b[0m                 self.dimension),\n\u001b[1;32m     55\u001b[0m             spatial_size=self.spatial_size)\n",
      "\u001b[0;32m/mnt/d/Documents/UCSD/SuLab/SparseConvNet/SparseConvNet/sparseconvnet/metadata.py\u001b[0m in \u001b[0;36mMetadata\u001b[0;34m(dim)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparseconvnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSCN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Metadata_%d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sparseconvnet.SCN' has no attribute 'Metadata_0'"
     ]
    }
   ],
   "source": [
    "for epoch in range(p['epoch'], p['n_epochs'] + 1):\n",
    "    model.train()\n",
    "    stats = {'n': 0, 'c': 0, 'loss': 0}\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = p['initial_lr'] * \\\n",
    "        math.exp((1 - epoch) * p['lr_decay'])\n",
    "        \n",
    "    scn.forward_pass_multiplyAdd_count=0\n",
    "    scn.forward_pass_hidden_states=0\n",
    "    start = time.time()\n",
    "    \n",
    "    for locations, features, targets in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        print(locations)\n",
    "        print(features)\n",
    "        print(targets)\n",
    "        predictions=model([locations,features.to(device)])\n",
    "        targets=targets.to(device)\n",
    "        loss = F.cross_entropy(predictions,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            predictions=predictions[targets>=0]\n",
    "            targets=targets[targets>=0]\n",
    "            stats['n']+=predictions.size(0)\n",
    "            stats['c']+=(predictions.max(1)[1]==targets).long().sum().item()\n",
    "            stats['loss']+=loss*predictions.size(0)\n",
    "        if epoch<=1:\n",
    "            print('train',loss.item(),stats['c']/stats['n'],stats['loss']/stats['n'])\n",
    "    print('train epoch',epoch,stats['c']/stats['n'],\n",
    "        'MegaMulAdd=',scn.forward_pass_multiplyAdd_count/795/1e6, 'MegaHidden',scn.forward_pass_hidden_states/795/1e6,'time=',time.time() - start,'s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd99307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playgrond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4d708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "691d825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc90bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
