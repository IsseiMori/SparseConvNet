{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f461ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sparseconvnet as scn\n",
    "\n",
    "\n",
    "# Use the GPU if there is one and sparseconvnet can use it, otherwise CPU\n",
    "use_cuda = torch.cuda.is_available() and scn.SCN.is_cuda_build()\n",
    "device = 'cuda:0' if use_cuda else 'cpu'\n",
    "if use_cuda:\n",
    "    print(\"Using CUDA.\")\n",
    "else:\n",
    "    print(\"Not using CUDA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6a4c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scn.Sequential().add(\n",
    "    scn.SparseVggNet(2, 1,\n",
    "                     [['C', 8], ['C', 8], ['MP', 3, 2],\n",
    "                      ['C', 16], ['C', 16], ['MP', 3, 2],\n",
    "                      ['C', 24], ['C', 24], ['MP', 3, 2]])\n",
    ").add(\n",
    "    scn.SubmanifoldConvolution(2, 24, 32, 3, False)\n",
    ").add(\n",
    "    scn.BatchNormReLU(32)\n",
    ").add(\n",
    "    scn.SparseToDense(2, 32)\n",
    ").to(device)\n",
    "\n",
    "# output will be 10x10\n",
    "inputSpatialSize = model.input_spatial_size(torch.LongTensor([10, 10]))\n",
    "input_layer = scn.InputLayer(2, inputSpatialSize)\n",
    "bl_input_layer = scn.BLInputLayer(2, inputSpatialSize)\n",
    "\n",
    "msgs = [[\" X   X  XXX  X    X    XX     X       X   XX   XXX   X    XXX   \",\n",
    "         \" X   X  X    X    X   X  X    X       X  X  X  X  X  X    X  X  \",\n",
    "         \" XXXXX  XX   X    X   X  X    X   X   X  X  X  XXX   X    X   X \",\n",
    "         \" X   X  X    X    X   X  X     X X X X   X  X  X  X  X    X  X  \",\n",
    "         \" X   X  XXX  XXX  XXX  XX       X   X     XX   X  X  XXX  XXX   \"],\n",
    "\n",
    "        [\" XXX              XXXXX      x   x     x  xxxxx  xxx \",\n",
    "         \" X  X  X   XXX       X       x   x x   x  x     x  x \",\n",
    "         \" XXX                X        x   xxxx  x  xxxx   xxx \",\n",
    "         \" X     X   XXX       X       x     x   x      x    x \",\n",
    "         \" X     X          XXXX   x   x     x   x  xxxx     x \",]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4027e070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Nx3 and Nx1 vectors to encode the messages above using InputLayer:\n",
    "locations = []\n",
    "features = []\n",
    "for batchIdx, msg in enumerate(msgs):\n",
    "    for y, line in enumerate(msg):\n",
    "        for x, c in enumerate(line):\n",
    "            if c == 'X':\n",
    "                locations.append([y, x, batchIdx])\n",
    "                features.append([1])\n",
    "locations = torch.LongTensor(locations)\n",
    "features = torch.FloatTensor(features).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f245f929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input SparseConvNetTensor: SparseConvNetTensor<<features=tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]], device='cuda:0'),features.shape=torch.Size([132, 1]),batch_locations=tensor([[ 0,  1,  0],\n",
      "        [ 0,  5,  0],\n",
      "        [ 0,  8,  0],\n",
      "        [ 0,  9,  0],\n",
      "        [ 0, 10,  0],\n",
      "        [ 0, 13,  0],\n",
      "        [ 0, 18,  0],\n",
      "        [ 0, 23,  0],\n",
      "        [ 0, 24,  0],\n",
      "        [ 0, 30,  0],\n",
      "        [ 0, 38,  0],\n",
      "        [ 0, 42,  0],\n",
      "        [ 0, 43,  0],\n",
      "        [ 0, 47,  0],\n",
      "        [ 0, 48,  0],\n",
      "        [ 0, 49,  0],\n",
      "        [ 0, 53,  0],\n",
      "        [ 0, 58,  0],\n",
      "        [ 0, 59,  0],\n",
      "        [ 0, 60,  0],\n",
      "        [ 1,  1,  0],\n",
      "        [ 1,  5,  0],\n",
      "        [ 1,  8,  0],\n",
      "        [ 1, 13,  0],\n",
      "        [ 1, 18,  0],\n",
      "        [ 1, 22,  0],\n",
      "        [ 1, 25,  0],\n",
      "        [ 1, 30,  0],\n",
      "        [ 1, 38,  0],\n",
      "        [ 1, 41,  0],\n",
      "        [ 1, 44,  0],\n",
      "        [ 1, 47,  0],\n",
      "        [ 1, 50,  0],\n",
      "        [ 1, 53,  0],\n",
      "        [ 1, 58,  0],\n",
      "        [ 1, 61,  0],\n",
      "        [ 2,  1,  0],\n",
      "        [ 2,  2,  0],\n",
      "        [ 2,  3,  0],\n",
      "        [ 2,  4,  0],\n",
      "        [ 2,  5,  0],\n",
      "        [ 2,  8,  0],\n",
      "        [ 2,  9,  0],\n",
      "        [ 2, 13,  0],\n",
      "        [ 2, 18,  0],\n",
      "        [ 2, 22,  0],\n",
      "        [ 2, 25,  0],\n",
      "        [ 2, 30,  0],\n",
      "        [ 2, 34,  0],\n",
      "        [ 2, 38,  0],\n",
      "        [ 2, 41,  0],\n",
      "        [ 2, 44,  0],\n",
      "        [ 2, 47,  0],\n",
      "        [ 2, 48,  0],\n",
      "        [ 2, 49,  0],\n",
      "        [ 2, 53,  0],\n",
      "        [ 2, 58,  0],\n",
      "        [ 2, 62,  0],\n",
      "        [ 3,  1,  0],\n",
      "        [ 3,  5,  0],\n",
      "        [ 3,  8,  0],\n",
      "        [ 3, 13,  0],\n",
      "        [ 3, 18,  0],\n",
      "        [ 3, 22,  0],\n",
      "        [ 3, 25,  0],\n",
      "        [ 3, 31,  0],\n",
      "        [ 3, 33,  0],\n",
      "        [ 3, 35,  0],\n",
      "        [ 3, 37,  0],\n",
      "        [ 3, 41,  0],\n",
      "        [ 3, 44,  0],\n",
      "        [ 3, 47,  0],\n",
      "        [ 3, 50,  0],\n",
      "        [ 3, 53,  0],\n",
      "        [ 3, 58,  0],\n",
      "        [ 3, 61,  0],\n",
      "        [ 4,  1,  0],\n",
      "        [ 4,  5,  0],\n",
      "        [ 4,  8,  0],\n",
      "        [ 4,  9,  0],\n",
      "        [ 4, 10,  0],\n",
      "        [ 4, 13,  0],\n",
      "        [ 4, 14,  0],\n",
      "        [ 4, 15,  0],\n",
      "        [ 4, 18,  0],\n",
      "        [ 4, 19,  0],\n",
      "        [ 4, 20,  0],\n",
      "        [ 4, 23,  0],\n",
      "        [ 4, 24,  0],\n",
      "        [ 4, 32,  0],\n",
      "        [ 4, 36,  0],\n",
      "        [ 4, 42,  0],\n",
      "        [ 4, 43,  0],\n",
      "        [ 4, 47,  0],\n",
      "        [ 4, 50,  0],\n",
      "        [ 4, 53,  0],\n",
      "        [ 4, 54,  0],\n",
      "        [ 4, 55,  0],\n",
      "        [ 4, 58,  0],\n",
      "        [ 4, 59,  0],\n",
      "        [ 4, 60,  0],\n",
      "        [ 0,  1,  1],\n",
      "        [ 0,  2,  1],\n",
      "        [ 0,  3,  1],\n",
      "        [ 0, 18,  1],\n",
      "        [ 0, 19,  1],\n",
      "        [ 0, 20,  1],\n",
      "        [ 0, 21,  1],\n",
      "        [ 0, 22,  1],\n",
      "        [ 1,  1,  1],\n",
      "        [ 1,  4,  1],\n",
      "        [ 1,  7,  1],\n",
      "        [ 1, 11,  1],\n",
      "        [ 1, 12,  1],\n",
      "        [ 1, 13,  1],\n",
      "        [ 1, 21,  1],\n",
      "        [ 2,  1,  1],\n",
      "        [ 2,  2,  1],\n",
      "        [ 2,  3,  1],\n",
      "        [ 2, 20,  1],\n",
      "        [ 3,  1,  1],\n",
      "        [ 3,  7,  1],\n",
      "        [ 3, 11,  1],\n",
      "        [ 3, 12,  1],\n",
      "        [ 3, 13,  1],\n",
      "        [ 3, 21,  1],\n",
      "        [ 4,  1,  1],\n",
      "        [ 4,  7,  1],\n",
      "        [ 4, 18,  1],\n",
      "        [ 4, 19,  1],\n",
      "        [ 4, 20,  1],\n",
      "        [ 4, 21,  1]]),batch_locations.shape=torch.Size([132, 3]),spatial size=tensor([87, 87])>>\n"
     ]
    }
   ],
   "source": [
    "input = input_layer([locations,features])\n",
    "print('Input SparseConvNetTensor:', input)\n",
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd4f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output SparseConvNetTensor: tensor([[[[1.4235, -0.0000, -0.0000,  ..., -0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, -0.0000,  ..., 2.0605, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.3359, 0.8802, -0.0000,  ..., -0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, 0.0460, -0.0000,  ..., 1.6741, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[-0.0000, 0.7537, 0.4120,  ..., 1.0200, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[-0.0000, -0.0000, 1.3364,  ..., 1.5711, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4341, 0.9432, -0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.1431, -0.0000, 1.2272,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[1.0976, -0.0000, 0.5612,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0000, -0.0000, 0.6624,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0973, -0.0000, -0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.5160, 1.1268, -0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
      "       device='cuda:0', grad_fn=<SparseToDenseFunctionBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Output is 2x32x10x10: our minibatch has 2 samples, the network has 32 output\n",
    "# feature planes, and 10x10 is the spatial size of the output.\n",
    "print('Output SparseConvNetTensor:', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3094f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
